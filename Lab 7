import pandas as pd 
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import LabelEncoder, OneHotEncoder 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LogisticRegression 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score

data = { 
'City': ['Mumbai', 'Delhi', 'Pune', 'Delhi', 'Chennai', 'Mumbai', 'Pune', 'Chennai'], 
'Experience_Years': [1, 3, 5, 2, 4, 6, 7, 8], 
'Department': ['HR', 'Finance', 'HR', 'Sales', 'Finance', 'HR', 'Sales', 'Finance'], 
'Selected': [0, 1, 1, 0, 1, 1, 0, 1]  # Target variable (0 = Not Selected, 1 = Selected) 
} 
df = pd.DataFrame(data) 
print("----- ORIGINAL DATASET -----") 
print(df) 
# Split dataset into features (X) and target (y) 
X = df[['City', 'Experience_Years', 'Department']] 
y = df['Selected']

# Label Encoding converts each category into a number. 
# Example: Mumbai -> 2, Delhi -> 1, etc. 
label_encoder = LabelEncoder() 
X_label_encoded = X.copy() 
X_label_encoded['City'] = label_encoder.fit_transform(X_label_encoded['City']) 
X_label_encoded['Department'] = label_encoder.fit_transform(X_label_encoded['Department']) 
print("\n----- AFTER LABEL ENCODING -----") 
print(X_label_encoded)

# One-Hot Encoding creates separate columns for each category. 
# Example: 'City_Mumbai', 'City_Delhi', etc. 
column_transformer = ColumnTransformer( 
transformers=[('encoder', OneHotEncoder(drop='first'), ['City', 'Department'])], 
remainder='passthrough' 
) 
X_onehot_encoded = column_transformer.fit_transform(X) 
X_onehot_encoded = pd.DataFrame(X_onehot_encoded.toarray() if hasattr(X_onehot_encoded, 
"toarray") else X_onehot_encoded) 
print("\n----- AFTER ONE-HOT ENCODING -----") 
print(X_onehot_encoded)

X_train_label, X_test_label, y_train, y_test = train_test_split(X_label_encoded, y, test_size=0.3, 
random_state=42) 
X_train_onehot, X_test_onehot, _, _ = train_test_split(X_onehot_encoded, y, test_size=0.3, 
random_state=42)

model_lr_label = LogisticRegression() 
model_dt_label = DecisionTreeClassifier(random_state=42) 
model_lr_label.fit(X_train_label, y_train) 
model_dt_label.fit(X_train_label, y_train) 
y_pred_lr_label = model_lr_label.predict(X_test_label) 
y_pred_dt_label = model_dt_label.predict(X_test_label) 

model_lr_onehot = LogisticRegression() 
model_dt_onehot = DecisionTreeClassifier(random_state=42) 
model_lr_onehot.fit(X_train_onehot, y_train) 
model_dt_onehot.fit(X_train_onehot, y_train) 
y_pred_lr_onehot = model_lr_onehot.predict(X_test_onehot) 
y_pred_dt_onehot = model_dt_onehot.predict(X_test_onehot)

acc_lr_label = accuracy_score(y_test, y_pred_lr_label) 
acc_dt_label = accuracy_score(y_test, y_pred_dt_label) 
acc_lr_onehot = accuracy_score(y_test, y_pred_lr_onehot) 
acc_dt_onehot = accuracy_score(y_test, y_pred_dt_onehot) 
print("\n----- MODEL ACCURACY COMPARISON -----") 
print("Logistic Regression (Label Encoded):", round(acc_lr_label, 2)) 
print("Decision Tree (Label Encoded):", round(acc_dt_label, 2)) 
print("Logistic Regression (One-Hot Encoded):", round(acc_lr_onehot, 2)) 
print("Decision Tree (One-Hot Encoded):", round(acc_dt_onehot, 2))

print("\n----- OBSERVATIONS -----") 
print(""" 
1. Label Encoding converts text categories into numeric codes. 
Example: HR = 0, Sales = 1, Finance = 2 
But this can confuse models like Logistic Regression because 
numbers may imply order or importance. 
2. One-Hot Encoding creates a separate column for each category. 
This avoids confusion and usually gives better performance 
with models like Logistic Regression. 
3. Decision Trees are less sensitive to encoding type, 
while Logistic Regression performs better with One-Hot Encoding. 
""")

df_label_encoded = pd.concat([X_label_encoded, y], axis=1) 
df_label_encoded.to_csv("Label_Encoded_Data.csv", index=False) 
df_onehot_encoded = pd.concat([X_onehot_encoded, y.reset_index(drop=True)], axis=1) 
df_onehot_encoded.to_csv("OneHot_Encoded_Data.csv", index=False) 
print("\nEncoded datasets saved successfully!")
